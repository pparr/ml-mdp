{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import hiive.mdptoolbox, hiive.mdptoolbox.example, hiive.mdptoolbox.mdp\n",
    "import hiive.mdptoolbox as mdptoolbox\n",
    "import hiive.visualization\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from example https://pymdptoolbox.readthedocs.io/en/latest/api/example.html#module-mdptoolbox.example\n",
    "# P probability matrix, R reward matrix\n",
    "# Default 3 states\n",
    "# 2 actions Wait (a0), Cut (a1).\n",
    "# state values 0-youngest, -1 oldest\n",
    "# TODO Make states a large value\n",
    "\n",
    "# make an environment that will work with AI gym\n",
    "P, R = mdptoolbox.example.forest(is_sparse=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0)\n",
      "(26.244000000000014, 29.484000000000016, 33.484000000000016)\n",
      "2\n",
      "0.002960681915283203\n"
     ]
    }
   ],
   "source": [
    "# Value Iteration\n",
    "\n",
    "# hparams\n",
    "# learning rate\n",
    "discount = [0.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "#stopping factor\n",
    "epsilon = [.01, .001, .0001, .00001]\n",
    "\n",
    "best_hparams = {'e': -1, 'd': -1, 'won': -1.0, 'moves': 0, 'iters': 0, \n",
    "                'time': 0.0, 'policy': None, 'value': None}\n",
    "\n",
    "vi = mdptoolbox.mdp.ValueIteration(P, R, 0.96)\n",
    "vi.run()\n",
    "#expected = (5.93215488, 9.38815488, 13.38815488)\n",
    "#all(expected[k] - vi.V[k] < 1e-12 for k in range(len(expected)))\n",
    "print(pi.policy)\n",
    "print(pi.V)\n",
    "print(pi.iter)\n",
    "print(pi.time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0)\n",
      "(26.244000000000014, 29.484000000000016, 33.484000000000016)\n",
      "2\n",
      "0.002960681915283203\n"
     ]
    }
   ],
   "source": [
    "# Policy Iteration\n",
    "pi = mdptoolbox.mdp.PolicyIteration(P, R, 0.9)\n",
    "pi.run()\n",
    "#expected = (26.244000000000014, 29.484000000000016, 33.484000000000016)\n",
    "#print(expected)\n",
    "#all(expected[k] - pi.V[k] < 1e-12 for k in range(len(expected)))\n",
    "print(pi.policy)\n",
    "print(pi.V)\n",
    "print(pi.iter)\n",
    "print(pi.time)\n",
    "#V (tuple) – value function\n",
    "#policy (tuple) – optimal policy\n",
    "#iter (int) – number of done iterations\n",
    "#time (float) – used CPU time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
